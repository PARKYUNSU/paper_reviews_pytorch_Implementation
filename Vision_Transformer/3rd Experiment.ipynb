{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNOx3Ex3KN2B",
        "outputId": "d36a1feb-6eea-4012-f505-0f51cbdb6695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Vision_Transformer'...\n",
            "remote: Enumerating objects: 532, done.\u001b[K\n",
            "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 532 (delta 156), reused 125 (delta 71), pack-reused 311 (from 1)\u001b[K\n",
            "Receiving objects: 100% (532/532), 2.02 MiB | 12.14 MiB/s, done.\n",
            "Resolving deltas: 100% (323/323), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PARKYUNSU/Vision_Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yiMADZyKRLm",
        "outputId": "cf7f6f29-1589-445a-ad31-6a7cbffcec1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-09 07:06:07--  https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.124, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/google/vit-base-patch16-224-in21k/84066da0f5d8ff1cc494c660d4693141fae2e356535bf18a14d9fc00a055a6a1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1739088367&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTA4ODM2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvdml0LWJhc2UtcGF0Y2gxNi0yMjQtaW4yMWsvODQwNjZkYTBmNWQ4ZmYxY2M0OTRjNjYwZDQ2OTMxNDFmYWUyZTM1NjUzNWJmMThhMTRkOWZjMDBhMDU1YTZhMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=f3GB1QT64FUd3h8MRucdNz9NKuSn39EqD1a9K7dz%7EpuKQadD0bqlsCSxqrG8VCzUhSa4YsdldfgnuLxVLTqESfL%7ElmHYqtAoh3PiWx3YbUwhOxNM025%7ErM7HLe27FHu8F4BdgH7MOnlxcgzpGtueWVbM5julUxvrb75XpfLDJtX6rwN8pRp2tZOHpcrSroNO%7ENTh5zI-t3ruTR%7EBvaWaJ5qhNmukBCofYxodQ9XROKjim-8qNF1nP2QVnkH8zLJkFRbl2B%7Ey1WE7mxeDgQnEcSprylwbvf5Rz5VkkDkRcCgjAlNMhH7ERwmPkhtRV0O%7ExGHZPGpWIqCM%7EKLE9cn3xQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-02-09 07:06:07--  https://cdn-lfs.hf.co/google/vit-base-patch16-224-in21k/84066da0f5d8ff1cc494c660d4693141fae2e356535bf18a14d9fc00a055a6a1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1739088367&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTA4ODM2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9nb29nbGUvdml0LWJhc2UtcGF0Y2gxNi0yMjQtaW4yMWsvODQwNjZkYTBmNWQ4ZmYxY2M0OTRjNjYwZDQ2OTMxNDFmYWUyZTM1NjUzNWJmMThhMTRkOWZjMDBhMDU1YTZhMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=f3GB1QT64FUd3h8MRucdNz9NKuSn39EqD1a9K7dz%7EpuKQadD0bqlsCSxqrG8VCzUhSa4YsdldfgnuLxVLTqESfL%7ElmHYqtAoh3PiWx3YbUwhOxNM025%7ErM7HLe27FHu8F4BdgH7MOnlxcgzpGtueWVbM5julUxvrb75XpfLDJtX6rwN8pRp2tZOHpcrSroNO%7ENTh5zI-t3ruTR%7EBvaWaJ5qhNmukBCofYxodQ9XROKjim-8qNF1nP2QVnkH8zLJkFRbl2B%7Ey1WE7mxeDgQnEcSprylwbvf5Rz5VkkDkRcCgjAlNMhH7ERwmPkhtRV0O%7ExGHZPGpWIqCM%7EKLE9cn3xQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.160.225.92, 18.160.225.18, 18.160.225.14, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.160.225.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 345636463 (330M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/vit_base_patch16_224_in21k.pth’\n",
            "\n",
            "/content/sample_dat 100%[===================>] 329.62M   220MB/s    in 1.5s    \n",
            "\n",
            "2025-02-09 07:06:10 (220 MB/s) - ‘/content/sample_data/vit_base_patch16_224_in21k.pth’ saved [345636463/345636463]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/pytorch_model.bin -O /content/sample_data/vit_base_patch16_224_in21k.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhceJj-wKSSl",
        "outputId": "6c6f3e87-cfbd-488f-e4f4-1f0164d56f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ml-collections\n",
            "  Downloading ml_collections-1.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from ml-collections) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from ml-collections) (1.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from ml-collections) (6.0.2)\n",
            "Downloading ml_collections-1.0.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-collections\n",
            "Successfully installed ml-collections-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ml-collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbMCbKRJKUN9",
        "outputId": "8e72eae3-2027-4f49-e0b7-a93853fd27f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170M/170M [00:02<00:00, 70.3MB/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "/content/Vision_Transformer/main.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_weights = torch.load(args.pretrained_path, map_location=device)\n",
            "Warning: 'head/kernel' not found, skipping head weights load.\n",
            "Warning: 'head/bias' not found, skipping head bias load.\n",
            "Loaded weights with message: _IncompatibleKeys(missing_keys=['pos_embed', 'encoder.norm.weight', 'encoder.norm.bias', 'head.0.weight', 'head.0.bias'], unexpected_keys=['layernorm.weight', 'layernorm.bias', 'pooler.dense.weight', 'pooler.dense.bias'])\n",
            "Starting training...\n",
            "Training Epoch 1: 100%|███████████████████████████████████████████| 782/782 [06:01<00:00,  2.16it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [1/50] | Train Loss: 1.2152, Train Acc: 68.42% | Eval Loss: 0.2439, Eval Acc: 93.60%\n",
            "Training Epoch 2: 100%|███████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [2/50] | Train Loss: 0.9020, Train Acc: 82.77% | Eval Loss: 0.2284, Eval Acc: 94.84%\n",
            "Training Epoch 3: 100%|███████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [3/50] | Train Loss: 0.8665, Train Acc: 84.09% | Eval Loss: 0.2131, Eval Acc: 94.97%\n",
            "Training Epoch 4: 100%|███████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [4/50] | Train Loss: 0.8450, Train Acc: 85.32% | Eval Loss: 0.2434, Eval Acc: 94.43%\n",
            "Training Epoch 5: 100%|███████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [5/50] | Train Loss: 0.8283, Train Acc: 85.85% | Eval Loss: 0.2374, Eval Acc: 94.70%\n",
            "Training Epoch 6: 100%|███████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [6/50] | Train Loss: 0.8141, Train Acc: 86.25% | Eval Loss: 0.2180, Eval Acc: 95.16%\n",
            "Training Epoch 7: 100%|███████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [7/50] | Train Loss: 0.8059, Train Acc: 86.74% | Eval Loss: 0.2226, Eval Acc: 94.88%\n",
            "Training Epoch 8: 100%|███████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [8/50] | Train Loss: 0.7966, Train Acc: 87.10% | Eval Loss: 0.2157, Eval Acc: 95.07%\n",
            "Training Epoch 9: 100%|███████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [9/50] | Train Loss: 0.7826, Train Acc: 87.69% | Eval Loss: 0.2168, Eval Acc: 95.19%\n",
            "Training Epoch 10: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [10/50] | Train Loss: 0.7801, Train Acc: 87.88% | Eval Loss: 0.2115, Eval Acc: 95.27%\n",
            "Training Epoch 11: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [11/50] | Train Loss: 0.7669, Train Acc: 88.43% | Eval Loss: 0.2208, Eval Acc: 95.04%\n",
            "Training Epoch 12: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [12/50] | Train Loss: 0.7683, Train Acc: 88.29% | Eval Loss: 0.2159, Eval Acc: 95.18%\n",
            "Training Epoch 13: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [13/50] | Train Loss: 0.7636, Train Acc: 88.44% | Eval Loss: 0.2210, Eval Acc: 95.64%\n",
            "Training Epoch 14: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [14/50] | Train Loss: 0.7591, Train Acc: 88.72% | Eval Loss: 0.2146, Eval Acc: 95.42%\n",
            "Training Epoch 15: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [15/50] | Train Loss: 0.7459, Train Acc: 89.32% | Eval Loss: 0.2273, Eval Acc: 95.00%\n",
            "Training Epoch 16: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [16/50] | Train Loss: 0.7507, Train Acc: 88.94% | Eval Loss: 0.2153, Eval Acc: 95.25%\n",
            "Training Epoch 17: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [17/50] | Train Loss: 0.7434, Train Acc: 89.41% | Eval Loss: 0.2423, Eval Acc: 94.38%\n",
            "Training Epoch 18: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [18/50] | Train Loss: 0.7380, Train Acc: 89.62% | Eval Loss: 0.2409, Eval Acc: 94.74%\n",
            "Training Epoch 19: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [19/50] | Train Loss: 0.7351, Train Acc: 89.64% | Eval Loss: 0.2089, Eval Acc: 95.37%\n",
            "Training Epoch 20: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [20/50] | Train Loss: 0.7345, Train Acc: 89.70% | Eval Loss: 0.2128, Eval Acc: 95.64%\n",
            "Training Epoch 21: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [21/50] | Train Loss: 0.7333, Train Acc: 89.81% | Eval Loss: 0.2037, Eval Acc: 95.67%\n",
            "Training Epoch 22: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [22/50] | Train Loss: 0.7275, Train Acc: 89.98% | Eval Loss: 0.2128, Eval Acc: 95.53%\n",
            "Training Epoch 23: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [23/50] | Train Loss: 0.7262, Train Acc: 90.04% | Eval Loss: 0.2167, Eval Acc: 95.38%\n",
            "Training Epoch 24: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [24/50] | Train Loss: 0.7210, Train Acc: 90.41% | Eval Loss: 0.2097, Eval Acc: 95.48%\n",
            "Training Epoch 25: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [25/50] | Train Loss: 0.7177, Train Acc: 90.49% | Eval Loss: 0.2199, Eval Acc: 95.39%\n",
            "Training Epoch 26: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [26/50] | Train Loss: 0.7188, Train Acc: 90.38% | Eval Loss: 0.2421, Eval Acc: 94.60%\n",
            "Training Epoch 27: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [27/50] | Train Loss: 0.7147, Train Acc: 90.49% | Eval Loss: 0.2465, Eval Acc: 94.54%\n",
            "Training Epoch 28: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [28/50] | Train Loss: 0.7079, Train Acc: 90.83% | Eval Loss: 0.2495, Eval Acc: 94.36%\n",
            "Training Epoch 29: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [29/50] | Train Loss: 0.7087, Train Acc: 90.89% | Eval Loss: 0.2318, Eval Acc: 95.12%\n",
            "Training Epoch 30: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [30/50] | Train Loss: 0.7113, Train Acc: 90.74% | Eval Loss: 0.2604, Eval Acc: 94.43%\n",
            "Training Epoch 31: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [31/50] | Train Loss: 0.7112, Train Acc: 90.74% | Eval Loss: 0.2307, Eval Acc: 95.05%\n",
            "Training Epoch 32: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [32/50] | Train Loss: 0.7063, Train Acc: 90.92% | Eval Loss: 0.2222, Eval Acc: 95.15%\n",
            "Training Epoch 33: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [33/50] | Train Loss: 0.7044, Train Acc: 91.05% | Eval Loss: 0.2310, Eval Acc: 95.26%\n",
            "Training Epoch 34: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [34/50] | Train Loss: 0.7042, Train Acc: 91.10% | Eval Loss: 0.2162, Eval Acc: 95.68%\n",
            "Training Epoch 35: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [35/50] | Train Loss: 0.6977, Train Acc: 91.38% | Eval Loss: 0.2336, Eval Acc: 94.86%\n",
            "Training Epoch 36: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [36/50] | Train Loss: 0.6944, Train Acc: 91.42% | Eval Loss: 0.2398, Eval Acc: 94.87%\n",
            "Training Epoch 37: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [37/50] | Train Loss: 0.6950, Train Acc: 91.47% | Eval Loss: 0.2346, Eval Acc: 94.87%\n",
            "Training Epoch 38: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [38/50] | Train Loss: 0.6916, Train Acc: 91.56% | Eval Loss: 0.2368, Eval Acc: 94.98%\n",
            "Training Epoch 39: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [39/50] | Train Loss: 0.6948, Train Acc: 91.41% | Eval Loss: 0.2376, Eval Acc: 94.76%\n",
            "Training Epoch 40: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [40/50] | Train Loss: 0.6905, Train Acc: 91.67% | Eval Loss: 0.2372, Eval Acc: 94.81%\n",
            "Training Epoch 41: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [41/50] | Train Loss: 0.6874, Train Acc: 91.76% | Eval Loss: 0.2332, Eval Acc: 95.35%\n",
            "Training Epoch 42: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [42/50] | Train Loss: 0.6887, Train Acc: 91.56% | Eval Loss: 0.2460, Eval Acc: 95.06%\n",
            "Training Epoch 43: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [43/50] | Train Loss: 0.6874, Train Acc: 91.67% | Eval Loss: 0.2406, Eval Acc: 95.27%\n",
            "Training Epoch 44: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [44/50] | Train Loss: 0.6840, Train Acc: 91.85% | Eval Loss: 0.2333, Eval Acc: 95.12%\n",
            "Training Epoch 45: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [45/50] | Train Loss: 0.6847, Train Acc: 91.79% | Eval Loss: 0.2557, Eval Acc: 94.50%\n",
            "Training Epoch 46: 100%|██████████████████████████████████████████| 782/782 [06:00<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [46/50] | Train Loss: 0.6805, Train Acc: 92.15% | Eval Loss: 0.2220, Eval Acc: 95.52%\n",
            "Training Epoch 47: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [47/50] | Train Loss: 0.6851, Train Acc: 91.84% | Eval Loss: 0.2398, Eval Acc: 95.15%\n",
            "Training Epoch 48: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.77it/s]\n",
            "Epoch [48/50] | Train Loss: 0.6814, Train Acc: 92.03% | Eval Loss: 0.2216, Eval Acc: 95.50%\n",
            "Training Epoch 49: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [49/50] | Train Loss: 0.6763, Train Acc: 92.19% | Eval Loss: 0.2233, Eval Acc: 95.39%\n",
            "Training Epoch 50: 100%|██████████████████████████████████████████| 782/782 [05:59<00:00,  2.17it/s]\n",
            "Evaluating: 100%|█████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.78it/s]\n",
            "Epoch [50/50] | Train Loss: 0.6791, Train Acc: 92.09% | Eval Loss: 0.2556, Eval Acc: 94.45%\n",
            "Training finished.\n",
            "Graph saved as 'loss_accuracy_plot.png'\n",
            "Model saved to fine_tuned_model.pth\n"
          ]
        }
      ],
      "source": [
        "!python /content/Vision_Transformer/main.py --mode train --pretrained_path /content/sample_data/vit_base_patch16_224_in21k.pth --epochs 50 --batch_size 64 --learning_rate 3e-4 --weight_decay 1e-4 --label_smoothing 0.1 --save_fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lctt-ndJOIVa",
        "outputId": "9c0617e4-eb18-4fd9-e50a-bdf806f7bbdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting visualization...\n",
            "/content/Vision_Transformer/model/vit.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_from(torch.load(pretrained_path, map_location=\"cpu\"))\n",
            "Warning: 'head/kernel' not found, skipping head weights load.\n",
            "Warning: 'head/bias' not found, skipping head bias load.\n",
            "Loaded weights with message: _IncompatibleKeys(missing_keys=['pos_embed'], unexpected_keys=[])\n",
            "Figure saved as attention_map.png\n"
          ]
        }
      ],
      "source": [
        "!python /content/Vision_Transformer/main.py --mode visualize --pretrained_path fine_tuned_model.pth  --image_path \"/content/data/my_image.jpg\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}