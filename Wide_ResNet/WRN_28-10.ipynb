{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:39.207434Z","iopub.status.busy":"2024-08-17T22:09:39.206716Z","iopub.status.idle":"2024-08-17T22:09:57.673177Z","shell.execute_reply":"2024-08-17T22:09:57.672301Z","shell.execute_reply.started":"2024-08-17T22:09:39.207402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in /Users/parkyunsu/anaconda3/envs/yg3/lib/python3.12/site-packages (1.5.1)\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","!pip install torchsummary\n","from torchsummary import summary\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:57.675374Z","iopub.status.busy":"2024-08-17T22:09:57.674807Z","iopub.status.idle":"2024-08-17T22:09:57.684401Z","shell.execute_reply":"2024-08-17T22:09:57.683382Z","shell.execute_reply.started":"2024-08-17T22:09:57.675346Z"},"trusted":true},"outputs":[],"source":["class Basicblock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride, dropRate):\n","        super(Basicblock, self).__init__()\n","        self.residual = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        )\n","        self.droprate = dropRate\n","        self.skip = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.skip = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","            \n","    def forward(self, x):\n","        identity =  x\n","        x = self.residual(x)\n","        if self.droprate > 0:\n","            x = F.dropout(x, p=self.droprate, training=self.training)\n","        x += self.skip(identity)\n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:57.685860Z","iopub.status.busy":"2024-08-17T22:09:57.685588Z","iopub.status.idle":"2024-08-17T22:09:57.699707Z","shell.execute_reply":"2024-08-17T22:09:57.698760Z","shell.execute_reply.started":"2024-08-17T22:09:57.685833Z"},"trusted":true},"outputs":[],"source":["class WideResNet(nn.Module):\n","    def __init__(self, depth, widen_factor, num_classes, dropRate):\n","        super(WideResNet, self).__init__()\n","        self.in_channels = 16\n","\n","        assert ((depth-4)%6 == 0)\n","        n = (depth-4) // 6\n","        k = widen_factor\n","#         print('|Wide-Resnet %dx%d' %(depth, k))\n","        nStages = [16, 16*k, 32*k, 64*k]\n","\n","        self.conv1 = nn.Conv2d(3,nStages[0], kernel_size=3, stride=1, padding=1, bias=False)\n","        self.layer1 = self._wide_layer(Basicblock, nStages[1], n, stride=1, dropRate=dropRate)\n","        self.layer2 = self._wide_layer(Basicblock, nStages[2], n, stride=2, dropRate=dropRate)\n","        self.layer3 = self._wide_layer(Basicblock, nStages[3], n, stride=2, dropRate=dropRate)\n","        self.bn1 = nn.BatchNorm2d(nStages[3])\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(nStages[3], num_classes)\n","        self.nStages = nStages[3]\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.bias.data.zero_()\n","\n","    def _wide_layer(self, block, out_channels, num_blocks, stride, dropRate):\n","        strides = [stride] + [1] * (int(num_blocks) - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride, dropRate))\n","            self.in_channels = out_channels\n","\n","        return nn.Sequential(*layers)\n","    \n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.relu(self.bn1(x))\n","        x = F.avg_pool2d(x, 8)\n","        x = x.view(-1, self.nStages)\n","        return self.fc(x)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:57.702062Z","iopub.status.busy":"2024-08-17T22:09:57.701698Z","iopub.status.idle":"2024-08-17T22:09:58.669653Z","shell.execute_reply":"2024-08-17T22:09:58.668611Z","shell.execute_reply.started":"2024-08-17T22:09:57.702039Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([1, 10])\n","Output: tensor([[ 0.0248, -0.0288,  0.2149, -0.0499,  0.2399,  0.2004,  0.2942,  0.1042,\n","          0.3768, -0.4669]], grad_fn=<AddmmBackward0>)\n"]}],"source":["model1 = WideResNet(28, 10, 10, 0.3)\n","random_input = torch.randn(1, 3, 32, 32)\n","\n","# Pass the random input through the model\n","output = model1(random_input)\n","\n","# Print the output\n","print(\"Output shape:\", output.shape)\n","print(\"Output:\", output)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:09:59.531792Z","iopub.status.busy":"2024-08-17T22:09:59.531372Z","iopub.status.idle":"2024-08-17T22:10:06.522072Z","shell.execute_reply":"2024-08-17T22:10:06.521289Z","shell.execute_reply.started":"2024-08-17T22:09:59.531759Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["path = '/Users/parkyunsu/gitfile/WideResNet/data'\n","if not os.path.exists(path):\n","    os.mkdir(path)\n","\n","# 데이터셋 전처리\n","transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),  # 수평으로 뒤집기\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","\n","\n","# CIFAR-10\n","trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = datasets.CIFAR10(root=path, train=False, download=True, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:10:06.524142Z","iopub.status.busy":"2024-08-17T22:10:06.523788Z","iopub.status.idle":"2024-08-17T22:10:06.533414Z","shell.execute_reply":"2024-08-17T22:10:06.532615Z","shell.execute_reply.started":"2024-08-17T22:10:06.524109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mps\n"]}],"source":["# MPS 또는 CPU 설정\n","device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n","print(device)\n","\n","# 모델을 MPS 또는 CPU로 이동\n","model1.to(device)\n","\n","# hyper parameters\n","initial_learning_rate = 0.1\n","\n","# loss, optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model1.parameters(), lr=initial_learning_rate, momentum=0.9, weight_decay=0.0005)\n","\n","# scheduler\n","scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120], gamma=0.1)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:10:06.535138Z","iopub.status.busy":"2024-08-17T22:10:06.534867Z","iopub.status.idle":"2024-08-17T22:10:06.549469Z","shell.execute_reply":"2024-08-17T22:10:06.548436Z","shell.execute_reply.started":"2024-08-17T22:10:06.535117Z"},"trusted":true},"outputs":[],"source":["def model_train(model1, data_loader, criterion, optimizer, epoch):\n","    model1.train()\n","\n","    global epoch_step\n","    running_size, running_loss, correct = 0.0, 0.0, 0.0\n","\n","    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","        pbar = tqdm(data_loader)\n","    else:\n","        pbar = data_loader\n","\n","    for images, labels in pbar:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model1(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","        running_size += images.size(0)\n","        correct += (outputs.argmax(1) == labels).sum().item()\n","\n","        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","            pbar.set_description('[Training] loss: ' +\n","                                f'{running_loss / running_size:.4f}, accuracy: ' +\n","                                f'{correct / running_size:.4f}')\n","        del images, labels, outputs, loss\n","        torch.mps.empty_cache()\n","        \n","    avg_accuracy = correct / running_size\n","    avg_loss = running_loss / running_size\n","    \n","    # Train Error Rate 계산\n","    train_error_rate = 100 * (1 - avg_accuracy)\n","    \n","    # Train Error Rate 출력 (epoch_step에 따라)\n","    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","        print(f'Train Error Rate: {train_error_rate:.2f}%')\n","\n","    return avg_loss, avg_accuracy, train_error_rate\n","\n","def model_eval(model1, data_loader, criterion, epoch):\n","    model1.eval()\n","    with torch.no_grad():\n","        running_loss, correct = 0.0, 0.0\n","\n","        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","            pbar = tqdm(data_loader)\n","        else:\n","            pbar = data_loader\n","\n","        for images, labels in pbar:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model1(images)\n","            pred = outputs.argmax(dim=1)\n","\n","            correct += torch.sum(pred == labels).item()\n","            running_loss += criterion(outputs, labels).item() * images.size(0)\n","\n","        accuracy = correct / len(data_loader.dataset)\n","        loss = running_loss / len(data_loader.dataset)\n","        \n","        # Test Error Rate 계산\n","        test_error_rate = 100 * (1 - accuracy)\n","        \n","        # Test Error Rate 출력 (epoch_step에 따라)\n","        if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","            print(f'Test Error Rate: {test_error_rate:.2f}%')\n","        \n","        return loss, accuracy, test_error_rate"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-17T22:10:06.552463Z","iopub.status.busy":"2024-08-17T22:10:06.552192Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Training] loss: 1.5693, accuracy: 0.4201: 100%|██████████| 391/391 [13:13<00:00,  2.03s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Error Rate: 57.99%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 79/79 [00:49<00:00,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Error Rate: 53.29%\n","epoch 001, Training loss: 1.5693, Training accuracy: 0.4201\n","Test loss: 1.6630, Test accuracy: 0.4671\n","Train error rate: 57.99%, Test error rate: 53.29%\n"]},{"name":"stderr","output_type":"stream","text":["\n","[Training] loss: 0.3644, accuracy: 0.8761: 100%|██████████| 391/391 [13:29<00:00,  2.07s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Error Rate: 12.39%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 79/79 [00:48<00:00,  1.64it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Error Rate: 18.32%\n","epoch 020, Training loss: 0.3644, Training accuracy: 0.8761\n","Test loss: 0.5800, Test accuracy: 0.8168\n","Train error rate: 12.39%, Test error rate: 18.32%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m epoch_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m     train_loss, train_accuracy, train_error_rate \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test_loss, test_accuracy, test_error_rate \u001b[38;5;241m=\u001b[39m model_eval(model1, testloader, criterion, epoch)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mappend([train_loss, test_loss])\n","Cell \u001b[0;32mIn[17], line 18\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(model1, data_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 18\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m running_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/yg3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:136\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    135\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/yg3/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/yg3/lib/python3.12/site-packages/torch/optim/optimizer.py:90\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 90\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","File \u001b[0;32m~/anaconda3/envs/yg3/lib/python3.12/site-packages/torch/optim/sgd.py:124\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    118\u001b[0m momentum_buffer_list: List[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    120\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    121\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[1;32m    122\u001b[0m )\n\u001b[0;32m--> 124\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n","File \u001b[0;32m~/anaconda3/envs/yg3/lib/python3.12/site-packages/torch/optim/sgd.py:299\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 299\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/yg3/lib/python3.12/site-packages/torch/optim/sgd.py:352\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m         grad \u001b[38;5;241m=\u001b[39m buf\n\u001b[0;32m--> 352\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 모델 학습 및 평가 코드\n","loss, accuracy, train_error_rates, test_error_rates = [], [], [], []\n","num_epochs = 200\n","epoch_step = 20\n","\n","for epoch in range(num_epochs):\n","    train_loss, train_accuracy, train_error_rate = model_train(model1, trainloader, criterion, optimizer, epoch)\n","    test_loss, test_accuracy, test_error_rate = model_eval(model1, testloader, criterion, epoch)\n","\n","    loss.append([train_loss, test_loss])\n","    accuracy.append([train_accuracy, test_accuracy])\n","    train_error_rates.append(train_error_rate)\n","    test_error_rates.append(test_error_rate)\n","\n","    scheduler.step()  # 스케줄러 업데이트\n","\n","    if (epoch + 1) % epoch_step == 0 or epoch == 0:\n","        print(f\"epoch {epoch+1:03d}, Training loss: \" + \n","              f\"{train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n","        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n","        print(f\"Train error rate: {train_error_rate:.2f}%, Test error rate: {test_error_rate:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train Error Rate와 Test Error Rate 그림 그리기\n","plt.figure(figsize=(10, 5)) \n","plt.plot(range(1, num_epochs + 1), train_error_rates, label='Train Error Rate')\n","plt.plot(range(1, num_epochs + 1), test_error_rates, label='Test Error Rate')\n","plt.xlabel('Epoch')\n","plt.ylabel('Error Rate (%)')\n","plt.title('Train and Test Error Rate Over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# 손실 그래프\n","train_losses, val_losses = zip(*loss)\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses, label='train')\n","plt.plot(val_losses, label='val')\n","plt.xlabel('Training Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.title('Train-Val Loss')\n","\n","# 정확도 그래프\n","train_accuracies, val_accuracies = zip(*accuracy)\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies, label='train')\n","plt.plot(val_accuracies, label='val')\n","plt.xlabel('Training Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Train-Val Accuracy')\n","\n","plt.tight_layout()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_train_error_rate = min(train_error_rates)\n","min_test_error_rate = min(test_error_rates)\n","\n","# 최소값 출력\n","print(f\"Minimum Train Error Rate: {min_train_error_rate:.2f}%\")\n","print(f\"Minimum Test Error Rate: {min_test_error_rate:.2f}%\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
