# Resnet

Link to Paper:

**â€œDeep Residual Learning for Image Recognitionâ€** - 2015

â€” Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun

Microsoft Research

https://arxiv.org/pdf/1512.03385v1


--------
Table of Contents

1. Introduction
2. Residual Learning
3. Network Architectures
4. Augmentation
5. Code
6. Conclusion

---

## **1. Introduction**



<img src="https://github.com/user-attachments/assets/2573acc9-8722-46db-86fb-88a49c5c09aa" width="700" height="400">


Fig.1

Deep convolutional neural networksì€ ì´ë¯¸ì§€ ì¸ì‹ ë° ë‹¤ì–‘í•œ ì»´í“¨í„° ë¹„ì „ ì‘ì—…ì— ë›°ì–´ë‚œ ë‘ê°ì„ ë‚´ì™”ìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ, ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜(degradtion problem) ë° ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ë§ˆì´í¬ë¡œ ì†Œí”„íŠ¸ ì—°êµ¬ì§„ë“¤ì€ í•´ê²°ë°©ë²•ìœ¼ë¡œ ê¸°ì¡´ ì‹ ê²½ë§ êµ¬ì¡°ì—ì„œ  Skip Connectionì„ í™œìš©í•œ Residual Learning(ì”ì°¨ í•™ìŠµ) í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ë” ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¤ê³ ì í–ˆìŠµë‹ˆë‹¤.

### **Traditional Architectureì˜ ë¬¸ì œì **

Skip connectionì„ ì´í•´í•˜ê¸° ì „ì— ì™œ í•„ìš”í•œì§€ì— ëŒ€í•´ ì•Œ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. VGGì™€ ê°™ì€ Architectureë¥¼ ì„¤ê³„í•  ë•Œ ê¹Šì„ìˆ˜ë¡ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê¹Šì´ê°€ ë„ˆë¬´ ê¹Šì–´ì§€ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ í•˜ë½í•˜ëŠ” ê²°ê³¼ë‚˜ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. 

Fig.1ì€ 56-layer networkëŠ” ì „ì²´ training ì ˆì°¨ ë™ì•ˆ ë†’ì€ training errorë¥¼ ê°–ìŠµë‹ˆë‹¤. 20-layer networkì˜ solution spaceëŠ” 56-layerì˜ subspaceì´ì§€ë§Œ, ë” ë†’ì€ errorê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.

VGGì™€ ê°™ì€ ì „í†µì ì¸ networkì—ì„œ ê¹Šì´ëŠ” ë§ì€ layersë¥¼ ê±¸ì³í•™ìŠµí•  ë•Œ ì„±ëŠ¥ì €í•˜ ë¬¸ì œì— ì˜í•´ ì œí•œë©ë‹ˆë‹¤. ResNetì—ì„œëŠ” short skip connectionsì„ ì‚¬ìš©í•˜ëŠ” residual architectures ë°©ë²•ì„ ì œê³µí•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ëª‡ ê°œì˜ layerë¥¼ ê±´ë„ˆ ë›°ì–´ ì—°ê²°í•´ non-linearitiesë¥¼ ì¶”ê°€í•˜ëŠ” skip connectionsì€ gradientê°€ layersë¥¼ ê±´ë„ˆë›°ì–´ ì—°ê²°ë  ìˆ˜ ìˆëŠ” shortcutsë¥¼ ë§Œë“¤ì–´ parametersë¥¼ networkì— deepí•˜ê²Œ ì—…ë°ì´íŠ¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 2. Residual Learning

### 1) Residual Block

<img src="https://github.com/user-attachments/assets/9e6f4fdb-52de-458e-aeb8-a10238df5934" width="400" height="300">

Fig.2

Residual Blockì€ ì…ë ¥ **ğ‘¥ê°€ ì§ì ‘ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬ë˜ëŠ” Skip connectionì„ í™œìš©í•©ë‹ˆë‹¤.**

**Residual Blockì˜ ì…ë ¥ ê°’ ğ‘¥ëŠ” ì¶œë ¥ ê°’ ğ¹(ğ‘¥) + ğ‘¥ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.**

ì—¬ê¸°ì„œ **ğ¹(ğ‘¥)ëŠ” ê¸°ì¡´ Plain blockê³¼ ë™ì¼í•˜ë©°, ğ‘¥ ëŠ” Identity mapping ì…ë‹ˆë‹¤.**

â†’ Identity mappingì€ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

í•¨ìˆ˜ *f* ê°€ì£¼ì–´ì¡Œì„ ë•Œ, **ğ‘¥ë¥¼  ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì—¬ ì¶œë ¥ë„ ğ‘¥ê°€ ë˜ëŠ” ê²ƒ**

**f(ğ‘¥) = ğ‘¥**

ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´,

**ğ»(ğ‘¥) = ğ¹(ğ‘¥) + ğ‘¥**

ì¦‰,

â†’ **ğ¹(ğ‘¥) = ğ»(ğ‘¥) âˆ’ ğ‘¥**

ì´ê²ƒì„ Residual Mapping(ì”ì°¨ ë§¤í•‘) ì´ë¼ê³  í•©ë‹ˆë‹¤. **ğ¹(ğ‘¥)ëŠ” ì¶œë ¥ ê°’ì—ì„œ ì…ë ¥ ê°’ì„ ëº€ ê°’ì´ë¯€ë¡œ ì”ì°¨ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì”ì°¨ í•™ìŠµì˜ ëª©í‘œëŠ” ì…ë ¥ ê°’ ğ‘¥ì— ëŒ€í•´ ì¶œë ¥ ê°’ ğ»(ğ‘¥)ê°€** Ground truth(ì‹¤ì œ ê°’)ì™€ ê°™ì•„ì§€ë„ë¡ ìµœì ì˜ **ğ¹(ğ‘¥) í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.**

í•™ìŠµ ê³¼ì • ìš”ì•½:

- **ğ»(ğ‘¥) = ğ¹(ğ‘¥) + ğ‘¥**
- **ğ‘¥ëŠ” ì…ë ¥ ê°’ê³¼ ë™ì¼í•˜ë¯€ë¡œ, ğ»(ğ‘¥) ì—ì„œ ì›í•˜ëŠ” ğ¹(ğ‘¥)ì„ ë„ì¶œí•  ìˆ˜ ìˆë‹¤ë©´** Ground truth(ì‹¤ì œ ê°’)ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ğ»(ğ‘¥)ì™€ ğ¹(ğ‘¥) í•™ìŠµì˜ ì°¨ì´
1. **ğ»(ğ‘¥) í•™ìŠµ:**
    
    **ğ»(ğ‘¥) = ğ‘¥ â†’ weight â†’ ReLU â†’ weight â†’ ğ»(ğ‘¥)**
    
2. **ğ¹(ğ‘¥) í•™ìŠµ:**
    
    **ğ¹(ğ‘¥) = ğ‘¥ â†’ weight â†’ ReLU â†’ weight â†’** **ğ¹(ğ‘¥)**
    

ê¸°ì¡´ ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ í†µí•´ ì…ë ¥ ê°’ì„ ë³€í˜•ì‹œì¼œ ìµœì¢… ì¶œë ¥ **ğ»(ğ‘¥)ì„ ì–»ëŠ” í•™ìŠµì—ì„œ, ì…ë ¥ ê°’ì„ ë³€í˜•ì‹œì¼œ ğ¹(ğ‘¥)ì„ ì–»ê³ , ì´ ğ¹(ğ‘¥)ê°€ 0ì´ ë˜ë„ë¡ í•˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ğ»(ğ‘¥)ê°€ ì…ë ¥ ê°’ ğ‘¥ì™€ ê°™ì•„ì§€ê²Œ ë©ë‹ˆë‹¤. ì¦‰, ğ»(ğ‘¥) = ğ¹(ğ‘¥) + ğ‘¥ ì´ë¯€ë¡œ, ğ¹(ğ‘¥)ë¥¼ 0ìœ¼ë¡œ ë§Œë“œëŠ” ì‰¬ìš´ ë¬¸ì œê°€ ë©ë‹ˆë‹¤.**

<img src="https://github.com/user-attachments/assets/1ebf5cc1-1640-41a1-adcb-f0eea0f68e32" width="600" height="350">

FIg.3

- ì™¼ìª½ ê·¸ë¦¼ì€ ì›ë˜ **ğ»(ğ‘¥)ë¥¼ ì§ì ‘ í•™ìŠµí•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤. ì…ë ¥ ğ‘¥ ê°€ ì—¬ëŸ¬ ì¸µì„ ê±°ì³ì„œ ìµœì¢… ì¶œë ¥ ğ»(ğ‘¥)ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ëŠ”** ê¸°ì¡´ì— í•™ìŠµí•œ ì •ë³´ë¥¼ ë³´ì¡´í•˜ì§€ ì•Šê³  ë³€í˜•ì‹œì¼œì„œ ìƒˆë¡­ê²Œ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
- ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì€ Residual Network êµ¬ì¡°ë¡œ, ì…ë ¥ **ğ‘¥ê°€ ì—¬ëŸ¬ ì¸µì„ ê±°ì³ ì”ì°¨ í•¨ìˆ˜ ğ¹(ğ‘¥)ë¥¼ í•™ìŠµí•˜ê³ , ìµœì¢… ì¶œë ¥ì€ ğ¹(ğ‘¥) + ğ‘¥ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ ì´ì „ ë ˆì´ì–´ì—ì„œ í•™ìŠµí–…ë˜ ì •ë³´ë¥¼ ì—°ê²°í•˜ì—¬ í•´ë‹¹ ì¸µì—ì„œëŠ” ì¶”ê°€ì ìœ¼ë¡œ í•™ìŠµí•´ì•¼ í•  ì •ë³´ë§Œë“¤ mapping í•™ìŠµí•©ë‹ˆë‹¤.**

ì”ì°¨ í•¨ìˆ˜ë¥¼ í•™ìŠµ í•˜ëŠ” ë°©ì‹ì€ ì…ë ¥ê³¼ ê°™ì€ **ğ‘¥**ê°€ ê·¸ëŒ€ë¡œ ì¶œë ¥ì— ì—°ê²°ë˜ì–´ íŒŒë¼ë¯¸í„° ìˆ˜ì— ì˜í–¥ì´ ì—†ê¸° ë•Œë¬¸ê³   **ğ»(ğ‘¥)ë¥¼ ì§ì ‘ í•™ìŠµí•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì•ˆì •ì , ê·¸ë˜ì„œ ì´ ë°©ì‹ìœ¼ë¡œ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œ** degradtion problem **ë¬¸ì œë¥¼ ì™„í•˜í•˜ì—¬ ê¹Šì€ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.**

### 2) Matching Dimensions

ë…¼ë¬¸ì—ì„œëŠ” ì°¨ì›ì„ ë§ì¶°ì•¼ì§€ Shortcut Connectionì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ê³ í•©ë‹ˆë‹¤.

ì¦‰,  **ğ‘¥ì™€ ğ¹ì˜ ì°¨ì›ì´ ë™ì¼í•´ì•¼í•©ë‹ˆë‹¤.** 

ë…¼ë¬¸ì—ì„œëŠ” *Ws*(ì •ì‚¬ê°í–‰ë ¬) ì‚¬ìš©í•´ì„œ ì°¨ì›ì„ ë§ì¶¥ë‹ˆë‹¤.

$$
y=F(x,{Wi})+Wsx
$$

<img src="https://github.com/user-attachments/assets/fb4f2041-eb63-4072-8af4-119a8266d9b2" width="350" height="300">

Fig.4

## 3. Network Architectures

<img src="https://github.com/user-attachments/assets/9c07b2a8-9a13-46ad-9b84-a253c20b2906" width="1000" height="450">

Fig.5

Residual Blockì„ ì´ìš©í•˜ì—¬ ë…¼ë¬¸ì—ì„œëŠ” 18-layer, 34-layer, 50-layer, 101-layer, 152-layerì˜ ResNetì„ ì œì•ˆ

18-layer ê²½ìš°ëŠ” 1 + 2 X 2 + 2 X 2 + 2 X 2 +2 X 2 + 1 = 18

<img src="https://github.com/user-attachments/assets/7ea771a9-332e-4fe6-ba41-1d124ce551d9" width="1000" height="300">

Fig.6

ì™¼ìª½ ê·¸ë˜í”„ëŠ” ë„¤íŠ¸ì›Œí¬ ë§ì´ ê¹Šì–´ì§€ë©´ì„œ ì—ëŸ¬ìœ¨(%)ì´ ì»¤ì§„ë‹¤. 34ì¸µì˜ ë„¤íŠ¸ì›Œí¬ê°€ 18ì¸µì˜ ë„¤íŠ¸ì›Œí¬ë³´ë‹¤ ì„±ëŠ¥ì´ ì•ˆì¢‹ë‹¤.

ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ëŠ” ResNet ë„¤íŠ¸ì›Œí¬ ë§ìœ¼ë¡œ ë§ì´ ê¹Šì–´ì§€ë©´ì„œ ì—ëŸ¬ìœ¨(%)ë„ ì‘ì•„ì¡Œë‹¤.

## 4. Agumentation and Training Setup

### 1) Agumentation

Image Size = 256 ~ 480 ëœë¤ ìƒ˜í”Œë§

Mean Subtraction - ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ê° í”½ì…€ ê°’ì—ì„œ í•´ë‹¹ í”½ì…€ì˜ í‰ê·  ê°’ì„ ë¹¼ì„œ ì •ê·œí™”

Horizontal Flip - ì´ë¯¸ì§€ ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ê¸°

224 x 224 ì´ë¯¸ì§€ë¡œ Random crop

Color Augmentation

### 2) Hyper Parameter

Optimizer - SGD

Batch_size - 256 ( ë…¼ë¬¸ì—ì„œëŠ” 256 ì´ì§€ë§Œ, ìì› í•œê³„ë¡œ 64ë¡œ ì§„í–‰)

weight decay - 0.001, momentum - 0.9

Learning_rate - 0.1 ë¡œ ì‹œì‘í•´ì„œ Validation error ê°€ ì¤„ì§€ ì•Šìœ¼ë©´ 10ë§Œí¼ ê³±í•˜ì—¬ì¤„ ì¤„ì„ (scheduler)

## 5. Code

Basic Block

```python
import torch
import torch.nn as nn

class BasicBlock(nn.Module):
    expansion_factor = 1
    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
                                   nn.BatchNorm2d(out_channels), 
                                   nn.ReLU())
        
        self.conv2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False), 
                                   nn.BatchNorm2d(out_channels), 
                                   nn.ReLU())

        self.residual = nn.Sequential()
        if stride != 1 or in_channels != out_channels * self.expansion_factor:
            self.residual = nn.Sequential(
                nn.Conv2d(in_channels, out_channels*self.expansion_factor, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels*self.expansion_factor))
        
        self.relu1 = nn.ReLU()
                
    def forward(self, x):
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)

        x += self.residual(identity) # shortcut connection
        x = self.relu1(x)
        return x
```

Bottle Neck Block

```python
class BottleNeck(nn.Module):
    expansion_factor=4
    def __init__(self, in_channels, out_channels, stride=1):
        super(BottleNeck, self).__init__()
        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),
                                   nn.BatchNorm2d(out_channels),
                                   nn.ReLU())
        
        self.conv2 = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
                                   nn.BatchNorm2d(out_channels),
                                   nn.ReLU())

        self.conv3 = nn.Sequential(nn.Conv2d(out_channels, out_channels * self.expansion_factor, kernel_size=1, stride=1, bias=False),
                                   nn.BatchNorm2d(out_channels * self.expansion_factor))

        self.residual = nn.Sequential()
        if stride != 1 or in_channels != out_channels * self.expansion_factor:
            self.residual = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * self.expansion_factor, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * self.expansion_factor))
            
        self.relu1 = nn.ReLU()

    def forward(self, x): 
        identity = x
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)

        x += self.residual(identity) # shortcut connection
        x = self.relu1(x)
        return x
```

Resnet Model

```python
class Resnet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(Resnet, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(num_features=64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
        
        self.conv2 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.conv3 = self._make_layer(block,128, num_blocks[1], stride=2)
        self.conv4 = self._make_layer(block,256, num_blocks[2], stride=2)
        self.conv5 = self._make_layer(block,512, num_blocks[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))
        self.fc = nn.Linear(512 * block.expansion_factor, num_classes)

        self._init_layer()

    def _make_layer(self, block, out_channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks -1) # [stride, 1, 1, ..., 1] 1ì€ num_block -1 ê°œ
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion_factor
        return nn.Sequential(*layers)
    
    def _init_layer(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x
```

```python
class Model:
    def resnet18(self):
        return Resnet(BasicBlock, [2, 2, 2, 2])

    def resnet34(self):
        return Resnet(BasicBlock, [3, 4, 6, 3])

    def resnet50(self):
        return Resnet(BottleNeck, [3, 4, 6, 3])

    def resnet101(self):
        return Resnet(BottleNeck, [3, 4, 23, 3])

    def resnet152(self):
        return Resnet(BottleNeck, [3, 8, 36, 3])
```

resnet50ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì¡° ì„¤ëª…

`BottleNeck`ì„ [3, 4, 6, 3]ì˜ í˜•íƒœë¡œ ë¸”ë¡ì„ êµ¬ì„±

1. ì²˜ìŒì€ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ 64 ì±„ë„ë¡œ ë°”ê¾¸ëŠ” 7 X 7 ì»¨ë³¼ë£¨ì…˜ ê³„ì¸µ ê³¼ MaxPooling ê³„ì¸µ
    
    Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
    
    BatchNorm2d(64)
    
    ReLU()
    
    MaxPool2d(kernel_size=3, stride=2, padding=1)
    

1. 64 ì±„ë„ë¡œ êµ¬ì„±ëœ 3ê°œì˜ `BottleNeck`
    
    _make_layer(BottleNeck, 64, 3, stride=1)
    

1. 128 ì±„ë„ë¡œ êµ¬ì„±ëœ 4ê°œì˜ `BottleNeck`
    
    _make_layer(BottleNeck, 128, 4, stride=2)
    

1. 256 ì±„ë„ë¡œ êµ¬ì„±ëœ 6ê°œì˜ `BottleNeck`
    
    _make_layer(BottleNeck, 256, 6, stride=2)
    
2. 512 ì±„ë„ë¡œ êµ¬ì„±ëœ 3ê°œì˜ `BottleNeck`
    
    _make_layer(BottleNeck, 512, 3, stride=2)
    

1. Adaptive Average Pooling â†’ ì¶œë ¥ í¬ê¸°ë¥¼ 1 X 1
    
    AdaptiveAvgPool2d(output_size=(1, 1))
    

1. ìµœì¢… ë¶„ë¥˜ ê³„ì¸µ: `512 X 4 (expansion_factor) = 2048`ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ `num_classes` ì¶œë ¥
    
    Linear(512 * 4, num_classes)
    

```python
model = Model().resnet152()
y = model(torch.randn(1, 3, 224, 224))
print (y.size()) # torch.Size([1, 10])
```

Mean Subtraction (ì´ë¯¸ì§€ì—ì„œ ê° í”½ì…€ ê°’ì— í•´ë‹¹í•˜ëŠ” í‰ê· ê³¼ í‘œì¤€í¸ì°¨ êµ¬í•˜ëŠ” ì½”ë“œ)

```python
path = '/kaggle/working/data'
if not os.path.exists(path):
    os.mkdir(path)

transfor = transforms.Compose([transforms.ToTensor()])
trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transfor)
testset = datasets.CIFAR10(root=path, train=False, download=True, transform=transfor)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=False, num_workers=2)
# ì´ë¯¸ì§€ í‰ê·  ë° í‘œì¤€í¸ì°¨ ê³„ì‚°
mean = torch.zeros(3)
std = torch.zeros(3)
nb_samples = 0.0
for images, _ in trainloader:
    batch_samples = images.size(0)
    images = images.view(batch_samples, images.size(1), -1)
    mean += images.mean(2).sum(0)
    std += images.std(2).sum(0)
    nb_samples += batch_samples
    
mean /= nb_samples
std /= nb_samples

mean = mean.numpy().tolist()
std = std.numpy().tolist()

print(mean)
print(std)

# mean = [0.4913995563983917, 0.48215848207473755, 0.44653093814849854]
#std = [0.20230084657669067, 0.19941289722919464, 0.20096157491207123]
```

Augmentation ë° ë°ì´í„°ì…‹ (CIFAR-10)

```python
# ë°ì´í„°ì…‹ ì „ì²˜ë¦¬
transform_train = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.875, 1.0)),  # Random crop 224x224
    transforms.RandomHorizontalFlip(),  # ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ê¸°
    transforms.Resize((224, 224)),  # í¬ê¸° ë³€ê²½
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # ìƒ‰ìƒ ë³€í˜•
    transforms.ToTensor(),
    transforms.Normalize(mean, std),  # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì´ìš©í•œ ì •ê·œí™”
])

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean, std),
])

# CIFAR-10
trainset = datasets.CIFAR10(root=path, train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)

testset = datasets.CIFAR10(root=path, train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)
```

Hyperparameters

```python
# CUDA ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# hyper parameters
initial_learnin_rate = 0.1 # ì´ˆê¸° learning_rate = 0.1
num_epochs = 50
epoch_step = 5

# Loss function, optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=initial_learnin_rate, momentum=0.9, weight_decay=0.0001) # weight_decay = 0.0001, momentum = 0.9

# scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True) # Validation errorê°€ ì¤„ì§€ ì•Šìœ¼ë©´ 10ë§Œí¼ ê³±í•˜ì—¬ ì¤„ì„
```

## 6. Conclusion

[Training] loss: 2.5621, accuracy: 0.1025: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.78it/s]
epoch 001, Training loss: 2.5621, Training accuracy: 0.1025
Test loss: 2.3088, Test accuracy: 0.0999

[Training] loss: 2.1157, accuracy: 0.1919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:48<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.77it/s]
epoch 005, Training loss: 2.1157, Training accuracy: 0.1919
Test loss: 2.2013, Test accuracy: 0.1653

[Training] loss: 1.1649, accuracy: 0.5863: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.75it/s]
epoch 010, Training loss: 1.1649, Training accuracy: 0.5863
Test loss: 1.0895, Test accuracy: 0.6163

[Training] loss: 0.6558, accuracy: 0.7725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.74it/s]
epoch 015, Training loss: 0.6558, Training accuracy: 0.7725
Test loss: 0.6743, Test accuracy: 0.7764

[Training] loss: 0.5116, accuracy: 0.8232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.74it/s]
epoch 020, Training loss: 0.5116, Training accuracy: 0.8232
Test loss: 0.5172, Test accuracy: 0.8243

[Training] loss: 0.4332, accuracy: 0.8494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.74it/s]
epoch 025, Training loss: 0.4332, Training accuracy: 0.8494
Test loss: 0.4895, Test accuracy: 0.8342

[Training] loss: 0.3809, accuracy: 0.8670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.76it/s]
epoch 030, Training loss: 0.3809, Training accuracy: 0.8670
Test loss: 0.5271, Test accuracy: 0.8292

[Training] loss: 0.3488, accuracy: 0.8792: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:49<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.77it/s]
epoch 035, Training loss: 0.3488, Training accuracy: 0.8792
Test loss: 0.5333, Test accuracy: 0.8242

[Training] loss: 0.3237, accuracy: 0.8880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:48<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.75it/s]
epoch 040, Training loss: 0.3237, Training accuracy: 0.8880
Test loss: 0.4719, Test accuracy: 0.8491

[Training] loss: 0.3008, accuracy: 0.8962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:48<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.76it/s]
epoch 045, Training loss: 0.3008, Training accuracy: 0.8962
Test loss: 0.3853, Test accuracy: 0.8724

[Training] loss: 0.2854, accuracy: 0.9020: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [09:48<00:00,  1.33it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:27<00:00,  5.76it/s]
epoch 050, Training loss: 0.2854, Training accuracy: 0.9020
Test loss: 0.4941, Test accuracy: 0.8374


<img src="https://github.com/user-attachments/assets/ff8c537d-9673-47f6-ada5-d0a4146127c4" width="1000" height="400">

